---
title: Templates Overview
description: Understand Vast.ai templatesâ€”saved configurations for Docker instances that specify images, launch modes, and initialization settings.
---

## What are Templates?

Vast.ai provides Linux Docker instances. A template is a saved set of initialization information that specifies what Docker image to load along with options that can only be set when the instance is created.

Templates allow you to:
- Save and reuse instance configurations
- Share configurations with others
- Earn referral credits through template sharing
- Quickly deploy standardized environments

## Template Categories

The primary instance configuration menu is accessible by clicking on the [Templates link](https://cloud.vast.ai/templates/) in the upper left navigation panel in the console.

### Recommended Templates

For typical use cases, we have recommended templates setup that will simply load a smart set of options for that use case. Simply click "select" to pick that template. Then you will be taken to the search interface to find a suitable GPU offer.

Common recommended templates include:
- PyTorch with Jupyter
- TensorFlow environments
- Stable Diffusion UIs
- LLM inference setups
- Development environments

### Popular Templates

The most popular templates used on Vast are in the popular section. These represent configurations that the community has found most useful.

### Recent Templates

The last template section is where your customized and selected templates are saved. Anytime you select a template, it is then saved in the "recent" section for easy access.

## Template Components

Every template configures:

1. **Docker Image**: The base container image
2. **Launch Mode**: How you'll connect (SSH, Jupyter, or Entrypoint)
3. **Docker Options**: Environment variables, ports, hostname
4. **On-start Script**: Commands to run at startup
5. **Disk Allocation**: Storage size for the instance
6. **Registry Settings**: Custom Docker registry authentication

## Using Templates

### Selecting a Template

1. Navigate to [Templates](https://cloud.vast.ai/templates/) or use the template selector on the search page
2. Browse recommended, popular, or recent templates
3. Click "Select" to use that template
4. The search page will filter to compatible machines

### Template Referral Links

Each template you create and make public can earn you referral credits with the [referral program](/documentation/reference/referral-program).

The referral link for each template is shown as a share icon on the template page or as a hash that you can copy in the search interface template menu.

Benefits of template referral links:
- User gets your template pre-selected
- Template is saved to their account
- You earn referral credits for new users
- Helps spread useful configurations

## Launch Modes in Templates

Templates support three launch modes that determine how you connect to your instance:

### SSH Launch Mode
- Provides terminal access
- Opens port 22 automatically
- Supports both proxy and direct connections
- Includes tmux session by default

### Jupyter Launch Mode
- Web-based notebook interface
- Opens port 8080 automatically
- Supports direct HTTPS with certificate
- Includes terminal access

### Entrypoint Mode
- Runs Docker's native entrypoint
- No automatic SSH/Jupyter setup
- For automated workloads
- Custom application deployment

For detailed launch mode information, see [Connection Methods](/documentation/instances/connect/overview).

## Template Best Practices

1. **Start with recommended templates**: Modify existing templates rather than starting from scratch
2. **Test before sharing**: Ensure your template works reliably
3. **Document your templates**: Add clear descriptions for shared templates
4. **Version your images**: Always specify image tags (avoid "latest")
5. **Size disk appropriately**: Remember disk size cannot be changed after creation
6. **Use environment variables**: Make templates flexible with env vars
7. **Include on-start scripts**: Automate setup tasks

## Common Template Configurations

### Development Environment
- Image: `nvidia/cuda:11.8.0-devel-ubuntu22.04`
- Launch: SSH
- Ports: Development server ports
- On-start: Install development tools

### Machine Learning Notebook
- Image: `pytorch/pytorch:latest`
- Launch: Jupyter
- Ports: TensorBoard, model serving
- On-start: Install additional libraries

### Production Inference
- Image: Custom model server image
- Launch: Entrypoint
- Ports: API endpoints
- On-start: Load model weights

## Next Steps

- [Create & Manage Templates](/documentation/instances/templates/manage-templates) - Build custom templates
- [Docker Environment](/documentation/instances/templates/docker-environment) - Configure Docker settings
- [Virtual Machines](/documentation/instances/templates/virtual-machines) - Use VM templates
- [Connection Methods](/documentation/instances/connect/overview) - Understand launch modes